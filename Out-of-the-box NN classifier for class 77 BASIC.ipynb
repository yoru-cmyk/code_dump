{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee708d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#from torchvision import datasets\n",
    "#from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa81e3f",
   "metadata": {},
   "source": [
    "#https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1215a",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c28a6",
   "metadata": {},
   "source": [
    "https://medium.com/@shashikachamod4u/excel-csv-to-pytorch-dataset-def496b6bcc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c651846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "csv = pd.read_csv(\"class77.csv\")\n",
    "csv = shuffle(csv)\n",
    "\n",
    "pre_full = csv\n",
    "pre_train=csv[0:2500]\n",
    "pre_test=csv[2500:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2065e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class csvDataset(Dataset):\n",
    "    def __init__(self,file):\n",
    "        file_out = file #pd.read_csv(file)\n",
    "        x=file_out.iloc[:,1:6].values\n",
    "        y=file_out.iloc[:,6:7].values\n",
    "\n",
    "        sc = StandardScaler()\n",
    "        x_train = sc.fit_transform(x)\n",
    "        y_train = y\n",
    "        \n",
    "        self.X_train = torch.tensor(x_train,dtype = torch.float32)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.X_train[idx].float(),self.y_train[idx].float()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68aa2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = csvDataset(pre_full)\n",
    "train = csvDataset(pre_train)\n",
    "test = csvDataset(pre_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a1a2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =500\n",
    "full_dataloader = DataLoader(full, batch_size=batch_size)\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1d9b6",
   "metadata": {},
   "source": [
    "If you want to load a model use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ea4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = NeuralNetwork()\n",
    "#model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137b44c",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7bc9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=11, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=11, out_features=2, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 11),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(11, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b066f-2241-473a-84f4-f5de910ceebc",
   "metadata": {},
   "source": [
    "Here we build the neural network itself. \n",
    "We use the https://en.wikipedia.org/wiki/Universal_approximation_theorem\n",
    "to get a rough idea of how big of a network we need.\n",
    "\n",
    "There are two versions of this : an older one from the 50s that deals only \n",
    "with shallow networks of arbitrary width (\"shallow neural nets\").\n",
    "And a newer one that deals with networks of arbitrary depth (e.g. deep neural nets). \n",
    "\n",
    "By using the UAT, I hope to answer the question: \n",
    "Am I in the money or am I completely in the left field of potatoes even before I reach the starting line? \n",
    "\n",
    "Because I want to respect the https://en.wikipedia.org/wiki/KISS_principle,\n",
    "so instead of starting right away with, \n",
    "\n",
    "In this case, the theorem says: the magic number is . \n",
    "In practice, it might be a little bit less, a little bit more, but we'll go with \"a little bit less\" in this case. \n",
    "\n",
    "I'm going to try the same architecture for two cases:\n",
    "One for class 77, the \"hard\" class, and one for class 16, the \"easy\" class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ad84c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=12, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=12, out_features=2, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358506a",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "\n",
    "https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "https://ruder.io/optimizing-gradient-descent/index.html#gradientdescentvariants\n",
    "\n",
    "https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
    "\n",
    "https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08d8df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False) #torch.optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323b1173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bc5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    print(size)\n",
    "    num_batches = len(dataloader)\n",
    "    #model.eval() will notify all your layers that you are in eval mode\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    #torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            #print(f\"this is y{y}\")\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            #print(f\"this is pred:{pred}\")\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            #print(f\"this is predargmax{pred.argmax(1)}\")\n",
    "            \n",
    "            final_pred = pred.argmax(1)            \n",
    "\n",
    "            \n",
    "            #correct += (pred.argmax(1) == y.flatten()).type(torch.float).sum().item()\n",
    "            #print(torch.eq(final_pred,y.flatten()))\n",
    "            correct += torch.eq(final_pred,y.flatten()).sum().item()\n",
    "\n",
    "            #print(f\"this is condition{(pred.argmax(1) == y)}\")\n",
    "            #print(f\"This is correct:{correct}\")\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847117c0",
   "metadata": {},
   "source": [
    "https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0a2fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for g in optimizer.param_groups:\n",
    "#    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac6a7006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.001532  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002398 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.001532  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002398 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.001535  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002414 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.001527  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002457 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.001533  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.002476 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.001537  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002456 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.001519  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002455 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.001521  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.4%, Avg loss: 0.002462 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.001535  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002429 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.001506  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.002468 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.001534  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002403 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.001518  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002404 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.001517  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002425 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.001524  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002445 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.001515  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.7%, Avg loss: 0.002471 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.001517  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002476 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.001512  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002486 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.001523  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.0%, Avg loss: 0.002414 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.001508  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002418 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.001525  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002420 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.001507  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002509 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.001565  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002501 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.001524  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002480 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.001514  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002488 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.001517  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002445 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.001520  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002444 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.001525  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.002470 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.001527  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002490 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.001518  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002522 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.001517  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002531 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.001518  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002505 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.001505  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 38.0%, Avg loss: 0.002494 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.001510  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002496 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.001506  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002494 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.001507  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002481 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.001492  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002502 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.001502  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002499 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.001496  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002446 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.001499  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002441 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.001501  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002459 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.001503  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002495 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.001513  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002515 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001500  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002525 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.001499  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.3%, Avg loss: 0.002541 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.001526  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002458 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.001498  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002469 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.001507  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002468 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.001498  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002499 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.001496  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002535 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.001503  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.002536 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.001491  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002530 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.001495  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002520 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.001484  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002542 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.001498  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.002540 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.001496  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.002534 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.001483  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.6%, Avg loss: 0.002476 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.001483  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.2%, Avg loss: 0.002464 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.001483  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002481 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.001493  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 0.002498 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.001493  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.002540 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.001503  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Avg loss: 0.002570 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.001509  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002598 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.001514  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.002519 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.001497  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002514 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.001509  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002511 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.001497  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002533 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.001493  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002550 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.001489  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002584 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.001501  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002576 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.001489  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002506 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.001488  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002481 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.001480  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 0.002507 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.001490  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002541 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.001486  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002570 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.001486  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002583 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.001488  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.3%, Avg loss: 0.002574 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.001476  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 0.002584 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.001482  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002566 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.001473  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002570 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.001474  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.2%, Avg loss: 0.002583 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.001477  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002590 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.001475  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002521 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001475  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002513 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.001477  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.6%, Avg loss: 0.002531 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.001480  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002555 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.001481  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.6%, Avg loss: 0.002589 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.001481  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002604 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.001474  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002608 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.001473  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.002526 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.001467  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.002509 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.001468  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002544 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.001475  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002587 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.001478  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.002598 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.001483  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.002616 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.001488  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.002631 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.001488  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.002636 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.001485  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 0.002572 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.001484  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.5%, Avg loss: 0.002549 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.001482  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.002564 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.001484  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002582 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.001479  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002605 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.001477  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.8%, Avg loss: 0.002619 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.001475  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.002610 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.001466  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.6%, Avg loss: 0.002601 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.001460  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002593 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.001463  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.002593 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.001456  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.002603 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002605 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.002609 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.002618 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002613 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.001460  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002620 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.001462  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002622 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 0.002616 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002613 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.002618 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.6%, Avg loss: 0.002618 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.002615 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.002615 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.001454  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.7%, Avg loss: 0.002613 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.001454  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.002622 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.001455  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.002633 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.7%, Avg loss: 0.002574 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002555 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.002575 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.002611 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.001467  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002642 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.001467  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002653 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.001463  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002660 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.001470  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.6%, Avg loss: 0.002589 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002567 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.001459  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.002581 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.001458  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002622 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.001465  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002639 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.001465  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002660 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 0.002666 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002604 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.001456  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002589 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002622 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.001474  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.002633 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.001464  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002662 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.001460  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002699 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.001489  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.3%, Avg loss: 0.002683 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002687 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.001456  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Avg loss: 0.002632 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.001470  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002596 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.001457  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.2%, Avg loss: 0.002621 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.001478  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002667 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.001513  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.002674 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.001476  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.001508  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.1%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.001468  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002764 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.001518  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002719 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.001472  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.001483  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002688 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.001464  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002704 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.001490  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002694 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.001477  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 0.002683 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.001450  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.002689 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.001452  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002711 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.001487  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002700 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.001475  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002689 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.001446  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002694 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.001454  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002646 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.001473  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002624 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.001456  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002658 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.001479  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002666 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002687 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.001472  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002710 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.001471  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002716 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.001450  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002707 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.001448  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002652 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.001452  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002634 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.001444  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002657 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.001454  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.3%, Avg loss: 0.002682 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.001452  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002685 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.001461  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002722 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.001472  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.001466  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.001463  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.001456  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.001451  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002724 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.001452  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002706 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.001443  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002699 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.001440  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002705 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.001449  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.0%, Avg loss: 0.002693 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.001436  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.8%, Avg loss: 0.002691 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.001436  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002695 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002696 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002705 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.001442  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002641 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.001438  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002624 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.001438  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002634 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.001441  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.002652 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.001442  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.002680 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.001446  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.002697 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.001442  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002719 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.001440  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002723 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.001438  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.002719 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.001436  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.0%, Avg loss: 0.002649 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.6%, Avg loss: 0.002629 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.001434  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 0.002637 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 0.002666 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.001439  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.0%, Avg loss: 0.002698 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.001441  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.002715 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.001440  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.001443  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.001440  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.0%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.6%, Avg loss: 0.002723 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.002721 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.002720 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 0.002717 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.001428  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002727 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.001429  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002664 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.001434  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002644 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.001438  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002644 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.8%, Avg loss: 0.002678 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 28.6%, Avg loss: 0.002710 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.001437  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.002725 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.001439  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.001444  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.001452  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.001449  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.4%, Avg loss: 0.002764 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.001447  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002776 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.001449  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.001437  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.002766 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.001437  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002670 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.0%, Avg loss: 0.002638 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.001427  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.002651 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.002675 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 0.002705 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.001429  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.001425  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002676 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.001425  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002657 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002672 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002692 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002716 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.001431  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002774 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002704 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002675 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.001421  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002691 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002711 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.001434  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.0%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002783 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.001444  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.5%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.001447  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.001444  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.0%, Avg loss: 0.002802 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002777 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.001425  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002773 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.1%, Avg loss: 0.002770 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.002774 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.002781 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.001420  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002702 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.002688 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 0.002695 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 0.002709 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.001434  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.001427  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 0.002794 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.001435  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.5%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.6%, Avg loss: 0.002801 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.001427  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.002782 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.001411  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002800 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.001421  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.001418  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.001415  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.7%, Avg loss: 0.002800 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.001413  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.002799 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.3%, Avg loss: 0.002804 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.001413  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.8%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.001421  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 0.002799 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.001410  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.001428  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.001418  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.5%, Avg loss: 0.002700 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.4%, Avg loss: 0.002701 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.001415  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.002714 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.001417  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.5%, Avg loss: 0.002755 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002781 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.001433  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.002844 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.001430  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.2%, Avg loss: 0.002847 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.001420  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.001412  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.3%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.001413  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 0.002801 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.9%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.001404  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.9%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.001405  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.002799 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.001410  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.001410  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002701 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.001418  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.6%, Avg loss: 0.002706 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.001418  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002785 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002814 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.002835 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.001419  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.001403  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.001410  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.001401  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.001411  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.001407  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002831 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.001409  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.2%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002839 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.001428  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.001400  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.002708 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.001404  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.2%, Avg loss: 0.002711 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.001404  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.3%, Avg loss: 0.002772 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.001420  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002781 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.001423  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.001426  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002866 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.001416  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.001407  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.5%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.001401  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.001398  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002847 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.001409  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.001414  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002716 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002716 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.001405  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.001417  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.001412  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.001422  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.001407  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002863 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.001400  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.001401  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002845 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.001405  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.3%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.6%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.001400  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002862 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.001411  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002723 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.001398  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002721 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.001405  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.001407  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.001427  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002845 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.001410  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.001418  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.5%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.001432  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002885 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.001420  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 0.002903 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.001424  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.001403  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.001403  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002866 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.001398  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.001397  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.001409  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.001408  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.001404  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 20.7%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.001407  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.001417  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 0.002864 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.001397  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002875 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.001393  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.9%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.001390  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.0%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.0%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.002864 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.002861 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.001390  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 0.002867 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.001397  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.001392  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002755 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.002826 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.001398  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.002869 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.001402  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002880 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.001390  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.002870 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.002867 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002867 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002877 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.001403  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.9%, Avg loss: 0.002727 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.0%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.001393  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 52.9%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002836 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.001401  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.001397  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.001412  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.001411  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002904 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.001406  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.002909 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.001397  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.002888 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.001393  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002872 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.5%, Avg loss: 0.002870 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002872 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.0%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.5%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.001393  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.001399  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002804 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.5%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.001401  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.002880 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002894 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.0%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.7%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002880 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002880 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.5%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.001392  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.001383  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.001383  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.001383  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.3%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002777 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.001392  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.001391  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.002882 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.001395  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002904 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.001396  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002920 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.001393  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002915 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002903 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.001383  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.7%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002894 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.001383  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002851 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.001390  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.001403  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002904 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.4%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.0%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002914 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.002909 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 0.002898 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.002901 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002902 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002907 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002911 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.002912 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.002902 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.001377  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.002903 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.001375  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002913 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.002914 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.001382  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.001371  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002918 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002918 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.001382  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002905 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.002911 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.002905 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.2%, Avg loss: 0.002917 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002915 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002922 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002921 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002917 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 0.002919 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.5%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.001371  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.6%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.4%, Avg loss: 0.002845 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002880 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 0.002888 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 28.9%, Avg loss: 0.002902 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.001388  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.8%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.001387  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.002933 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 0.002924 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 0.002907 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.002910 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.002903 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.002914 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.002926 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002927 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.001394  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002933 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.001381  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002784 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.002921 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.001389  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 0.002963 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 0.002933 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.001371  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.001375  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.001374  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002949 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.4%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.001363  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.9%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002957 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.001362  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002945 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.001365  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.001362  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.002955 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.001367  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.002826 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.001375  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.001384  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002905 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.001386  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.002958 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.001377  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.001376  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.5%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.002949 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002955 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.001382  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.001371  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.6%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.6%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.6%, Avg loss: 0.002960 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.3%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.002837 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.001365  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.001363  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.001378  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002913 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002949 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002984 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002960 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002960 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.2%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.001366  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002895 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.001380  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.0%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.001390  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.001370  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 41.5%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.001371  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.1%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.001363  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 0.002918 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.002928 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.9%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.8%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.001353  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.001369  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.001353  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.6%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.9%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 30.3%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002820 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 20.9%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.6%, Avg loss: 0.002911 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.0%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.3%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002990 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002988 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.7%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 28.8%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.001355  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.4%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.5%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.2%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.001350  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.2%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.8%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.001348  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.8%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.2%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.001350  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.001344  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.001349  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.7%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.2%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.001344  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 62.7%, Avg loss: 0.002788 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.002794 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.001350  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.1%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.6%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.001353  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 0.002990 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.002988 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.001339  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.001344  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.6%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.001352  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002989 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.001360  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.001372  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.001364  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.002872 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.001359  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.001354  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.001350  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.001340  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.001344  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.003000 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.003004 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.4%, Avg loss: 0.003012 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.4%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.003000 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.7%, Avg loss: 0.003003 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.001339  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.1%, Avg loss: 0.003004 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.001336  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.003007 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.003011 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.003011 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.001340  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.003004 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 0.003000 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.9%, Avg loss: 0.003004 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.003009 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.001336  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.003007 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 0.003012 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.6%, Avg loss: 0.003007 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.003013 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.001340  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.003034 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.001361  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.8%, Avg loss: 0.003024 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.001346  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.003015 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.003009 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.003024 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.003016 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.6%, Avg loss: 0.003025 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.003021 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.2%, Avg loss: 0.003029 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.001350  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.001342  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.001348  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.001348  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.001345  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.003029 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.001340  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.2%, Avg loss: 0.003040 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.001336  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.003037 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.003018 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.003013 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.003020 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.003044 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.001379  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.9%, Avg loss: 0.003023 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.001341  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.003016 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.9%, Avg loss: 0.003003 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.003005 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.003001 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.003007 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.003007 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.001337  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 0.003008 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.003022 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.001351  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.3%, Avg loss: 0.003017 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.003019 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.001357  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 0.003008 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.003003 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002998 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.003002 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.001332  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.003011 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.003003 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.003002 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002991 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.002990 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002994 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002999 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.003001 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.001332  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.003002 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002993 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002998 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.003001 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.003002 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.003004 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.001368  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 0.002917 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.001363  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.001362  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.001358  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.001373  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.001367  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.001347  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002911 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.001340  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.001332  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.001344  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.003015 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.001356  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.3%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002984 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002994 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002994 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002989 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002993 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.001334  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.5%, Avg loss: 0.002990 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.001338  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.001333  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.002967 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.001323  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.001325  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.002963 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.001323  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.9%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.001321  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002964 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.2%, Avg loss: 0.002957 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002958 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.001318  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.6%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.001330  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002957 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.001323  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.001318  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.8%, Avg loss: 0.002960 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.2%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.001317  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002778 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002721 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.001331  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.001336  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.0%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.002988 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.001318  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.8%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.0%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.6%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.3%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 38.5%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.1%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.001311  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.6%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.9%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.8%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.001318  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.5%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.8%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.001323  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.2%, Avg loss: 0.002884 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.001329  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.002904 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.001336  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002920 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.001335  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002984 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.003072 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.001385  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.001332  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.6%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.001324  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.001328  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002872 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.001327  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.002894 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 0.002910 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.001321  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.002917 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.001320  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002932 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.002943 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002949 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.001311  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.002971 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.001317  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002975 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.001317  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.5%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.001311  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.0%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002983 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.001308  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002976 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.002981 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.001305  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002982 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.001315  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.6%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.001308  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.002978 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.9%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.002974 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.6%, Avg loss: 0.002985 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002980 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.001317  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.5%, Avg loss: 0.002955 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.6%, Avg loss: 0.002963 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.001305  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.001310  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.6%, Avg loss: 0.002955 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.0%, Avg loss: 0.002958 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.6%, Avg loss: 0.002965 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.001303  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.002972 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.0%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 1001\n",
      "-------------------------------\n",
      "loss: 0.001304  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.9%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1002\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002961 \n",
      "\n",
      "Epoch 1003\n",
      "-------------------------------\n",
      "loss: 0.001303  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 1004\n",
      "-------------------------------\n",
      "loss: 0.001314  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 1005\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1006\n",
      "-------------------------------\n",
      "loss: 0.001305  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1007\n",
      "-------------------------------\n",
      "loss: 0.001305  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1008\n",
      "-------------------------------\n",
      "loss: 0.001322  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1009\n",
      "-------------------------------\n",
      "loss: 0.001303  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 1010\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1011\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.0%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 1012\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1013\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 38.2%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 1014\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1015\n",
      "-------------------------------\n",
      "loss: 0.001308  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.5%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1016\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 1017\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1018\n",
      "-------------------------------\n",
      "loss: 0.001298  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1019\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 1020\n",
      "-------------------------------\n",
      "loss: 0.001307  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.002962 \n",
      "\n",
      "Epoch 1021\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 1022\n",
      "-------------------------------\n",
      "loss: 0.001304  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 1023\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 1024\n",
      "-------------------------------\n",
      "loss: 0.001304  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 1025\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.6%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 1026\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 1027\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1028\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1029\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.5%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1030\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 1031\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002954 \n",
      "\n",
      "Epoch 1032\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002957 \n",
      "\n",
      "Epoch 1033\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.5%, Avg loss: 0.002956 \n",
      "\n",
      "Epoch 1034\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.002968 \n",
      "\n",
      "Epoch 1035\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 1036\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 1037\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002973 \n",
      "\n",
      "Epoch 1038\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002951 \n",
      "\n",
      "Epoch 1039\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 1040\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 1041\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 1042\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1043\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002943 \n",
      "\n",
      "Epoch 1044\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.5%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1045\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1046\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1047\n",
      "-------------------------------\n",
      "loss: 0.001291  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 1048\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.002945 \n",
      "\n",
      "Epoch 1049\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.6%, Avg loss: 0.002943 \n",
      "\n",
      "Epoch 1050\n",
      "-------------------------------\n",
      "loss: 0.001293  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.002938 \n",
      "\n",
      "Epoch 1051\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002939 \n",
      "\n",
      "Epoch 1052\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.002946 \n",
      "\n",
      "Epoch 1053\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002943 \n",
      "\n",
      "Epoch 1054\n",
      "-------------------------------\n",
      "loss: 0.001299  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002933 \n",
      "\n",
      "Epoch 1055\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1056\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1057\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.002673 \n",
      "\n",
      "Epoch 1058\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002709 \n",
      "\n",
      "Epoch 1059\n",
      "-------------------------------\n",
      "loss: 0.001305  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002783 \n",
      "\n",
      "Epoch 1060\n",
      "-------------------------------\n",
      "loss: 0.001308  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 1061\n",
      "-------------------------------\n",
      "loss: 0.001312  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002916 \n",
      "\n",
      "Epoch 1062\n",
      "-------------------------------\n",
      "loss: 0.001311  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002966 \n",
      "\n",
      "Epoch 1063\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002987 \n",
      "\n",
      "Epoch 1064\n",
      "-------------------------------\n",
      "loss: 0.001303  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002984 \n",
      "\n",
      "Epoch 1065\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.6%, Avg loss: 0.002977 \n",
      "\n",
      "Epoch 1066\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002969 \n",
      "\n",
      "Epoch 1067\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002958 \n",
      "\n",
      "Epoch 1068\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002957 \n",
      "\n",
      "Epoch 1069\n",
      "-------------------------------\n",
      "loss: 0.001293  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 1070\n",
      "-------------------------------\n",
      "loss: 0.001291  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002955 \n",
      "\n",
      "Epoch 1071\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.002950 \n",
      "\n",
      "Epoch 1072\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002959 \n",
      "\n",
      "Epoch 1073\n",
      "-------------------------------\n",
      "loss: 0.001306  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1074\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 1075\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 0.002963 \n",
      "\n",
      "Epoch 1076\n",
      "-------------------------------\n",
      "loss: 0.001298  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 0.002958 \n",
      "\n",
      "Epoch 1077\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 1078\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.002945 \n",
      "\n",
      "Epoch 1079\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1080\n",
      "-------------------------------\n",
      "loss: 0.001293  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002938 \n",
      "\n",
      "Epoch 1081\n",
      "-------------------------------\n",
      "loss: 0.001298  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 0.002925 \n",
      "\n",
      "Epoch 1082\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002933 \n",
      "\n",
      "Epoch 1083\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 1084\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.002925 \n",
      "\n",
      "Epoch 1085\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002929 \n",
      "\n",
      "Epoch 1086\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002918 \n",
      "\n",
      "Epoch 1087\n",
      "-------------------------------\n",
      "loss: 0.001294  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1088\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002919 \n",
      "\n",
      "Epoch 1089\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.002929 \n",
      "\n",
      "Epoch 1090\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.002925 \n",
      "\n",
      "Epoch 1091\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002953 \n",
      "\n",
      "Epoch 1092\n",
      "-------------------------------\n",
      "loss: 0.001319  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002970 \n",
      "\n",
      "Epoch 1093\n",
      "-------------------------------\n",
      "loss: 0.001316  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1094\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1095\n",
      "-------------------------------\n",
      "loss: 0.001296  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.1%, Avg loss: 0.002945 \n",
      "\n",
      "Epoch 1096\n",
      "-------------------------------\n",
      "loss: 0.001300  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 1097\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.8%, Avg loss: 0.002928 \n",
      "\n",
      "Epoch 1098\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002929 \n",
      "\n",
      "Epoch 1099\n",
      "-------------------------------\n",
      "loss: 0.001286  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002926 \n",
      "\n",
      "Epoch 1100\n",
      "-------------------------------\n",
      "loss: 0.001291  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 1101\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1102\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.002921 \n",
      "\n",
      "Epoch 1103\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.002914 \n",
      "\n",
      "Epoch 1104\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.4%, Avg loss: 0.002918 \n",
      "\n",
      "Epoch 1105\n",
      "-------------------------------\n",
      "loss: 0.001295  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.3%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 1106\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002888 \n",
      "\n",
      "Epoch 1107\n",
      "-------------------------------\n",
      "loss: 0.001301  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002922 \n",
      "\n",
      "Epoch 1108\n",
      "-------------------------------\n",
      "loss: 0.001343  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 1109\n",
      "-------------------------------\n",
      "loss: 0.001326  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 1110\n",
      "-------------------------------\n",
      "loss: 0.001309  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.002799 \n",
      "\n",
      "Epoch 1111\n",
      "-------------------------------\n",
      "loss: 0.001313  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002832 \n",
      "\n",
      "Epoch 1112\n",
      "-------------------------------\n",
      "loss: 0.001317  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.002823 \n",
      "\n",
      "Epoch 1113\n",
      "-------------------------------\n",
      "loss: 0.001304  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 1114\n",
      "-------------------------------\n",
      "loss: 0.001294  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 1115\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.002836 \n",
      "\n",
      "Epoch 1116\n",
      "-------------------------------\n",
      "loss: 0.001290  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 1117\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1118\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1119\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1120\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002871 \n",
      "\n",
      "Epoch 1121\n",
      "-------------------------------\n",
      "loss: 0.001293  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 1122\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 1123\n",
      "-------------------------------\n",
      "loss: 0.001286  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002872 \n",
      "\n",
      "Epoch 1124\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 1125\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 1126\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.4%, Avg loss: 0.002882 \n",
      "\n",
      "Epoch 1127\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 1128\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.002882 \n",
      "\n",
      "Epoch 1129\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.002877 \n",
      "\n",
      "Epoch 1130\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 1131\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.8%, Avg loss: 0.002888 \n",
      "\n",
      "Epoch 1132\n",
      "-------------------------------\n",
      "loss: 0.001286  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.5%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 1133\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1134\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1135\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.9%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1136\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002887 \n",
      "\n",
      "Epoch 1137\n",
      "-------------------------------\n",
      "loss: 0.001286  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.8%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 1138\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 1139\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1140\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 1141\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.002895 \n",
      "\n",
      "Epoch 1142\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 1143\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.7%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 1144\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 1145\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 1146\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1147\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.7%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 1148\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 1149\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.5%, Avg loss: 0.002895 \n",
      "\n",
      "Epoch 1150\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 30.9%, Avg loss: 0.002895 \n",
      "\n",
      "Epoch 1151\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1152\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.0%, Avg loss: 0.002896 \n",
      "\n",
      "Epoch 1153\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.8%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 1154\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.5%, Avg loss: 0.002903 \n",
      "\n",
      "Epoch 1155\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.0%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 1156\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002900 \n",
      "\n",
      "Epoch 1157\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.4%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 1158\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 1159\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.4%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 1160\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002885 \n",
      "\n",
      "Epoch 1161\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002896 \n",
      "\n",
      "Epoch 1162\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002901 \n",
      "\n",
      "Epoch 1163\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.002895 \n",
      "\n",
      "Epoch 1164\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 0.002691 \n",
      "\n",
      "Epoch 1165\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.002643 \n",
      "\n",
      "Epoch 1166\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002669 \n",
      "\n",
      "Epoch 1167\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.9%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1168\n",
      "-------------------------------\n",
      "loss: 0.001297  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1169\n",
      "-------------------------------\n",
      "loss: 0.001294  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002881 \n",
      "\n",
      "Epoch 1170\n",
      "-------------------------------\n",
      "loss: 0.001291  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002920 \n",
      "\n",
      "Epoch 1171\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002945 \n",
      "\n",
      "Epoch 1172\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002949 \n",
      "\n",
      "Epoch 1173\n",
      "-------------------------------\n",
      "loss: 0.001288  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1174\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.2%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1175\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002943 \n",
      "\n",
      "Epoch 1176\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.0%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1177\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 1178\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.002948 \n",
      "\n",
      "Epoch 1179\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1180\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1181\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.8%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1182\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1183\n",
      "-------------------------------\n",
      "loss: 0.001275  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1184\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1185\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1186\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002930 \n",
      "\n",
      "Epoch 1187\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.002927 \n",
      "\n",
      "Epoch 1188\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Avg loss: 0.002929 \n",
      "\n",
      "Epoch 1189\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1190\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1191\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 21.9%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1192\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1193\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1194\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1195\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 1196\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 1197\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002942 \n",
      "\n",
      "Epoch 1198\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002934 \n",
      "\n",
      "Epoch 1199\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1200\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 1201\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1202\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.002947 \n",
      "\n",
      "Epoch 1203\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 1204\n",
      "-------------------------------\n",
      "loss: 0.001270  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.1%, Avg loss: 0.002944 \n",
      "\n",
      "Epoch 1205\n",
      "-------------------------------\n",
      "loss: 0.001286  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.0%, Avg loss: 0.002952 \n",
      "\n",
      "Epoch 1206\n",
      "-------------------------------\n",
      "loss: 0.001293  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.4%, Avg loss: 0.002941 \n",
      "\n",
      "Epoch 1207\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1208\n",
      "-------------------------------\n",
      "loss: 0.001285  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.002938 \n",
      "\n",
      "Epoch 1209\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002940 \n",
      "\n",
      "Epoch 1210\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002937 \n",
      "\n",
      "Epoch 1211\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002935 \n",
      "\n",
      "Epoch 1212\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 0.002936 \n",
      "\n",
      "Epoch 1213\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002907 \n",
      "\n",
      "Epoch 1214\n",
      "-------------------------------\n",
      "loss: 0.001272  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.8%, Avg loss: 0.002901 \n",
      "\n",
      "Epoch 1215\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002911 \n",
      "\n",
      "Epoch 1216\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002915 \n",
      "\n",
      "Epoch 1217\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.7%, Avg loss: 0.002898 \n",
      "\n",
      "Epoch 1218\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.4%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 1219\n",
      "-------------------------------\n",
      "loss: 0.001275  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002893 \n",
      "\n",
      "Epoch 1220\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.7%, Avg loss: 0.002890 \n",
      "\n",
      "Epoch 1221\n",
      "-------------------------------\n",
      "loss: 0.001291  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 1222\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 1223\n",
      "-------------------------------\n",
      "loss: 0.001274  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002875 \n",
      "\n",
      "Epoch 1224\n",
      "-------------------------------\n",
      "loss: 0.001275  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.0%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 1225\n",
      "-------------------------------\n",
      "loss: 0.001269  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1226\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002899 \n",
      "\n",
      "Epoch 1227\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002901 \n",
      "\n",
      "Epoch 1228\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.1%, Avg loss: 0.002906 \n",
      "\n",
      "Epoch 1229\n",
      "-------------------------------\n",
      "loss: 0.001283  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.4%, Avg loss: 0.002892 \n",
      "\n",
      "Epoch 1230\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 0.002904 \n",
      "\n",
      "Epoch 1231\n",
      "-------------------------------\n",
      "loss: 0.001275  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002909 \n",
      "\n",
      "Epoch 1232\n",
      "-------------------------------\n",
      "loss: 0.001289  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002905 \n",
      "\n",
      "Epoch 1233\n",
      "-------------------------------\n",
      "loss: 0.001282  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.002896 \n",
      "\n",
      "Epoch 1234\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002897 \n",
      "\n",
      "Epoch 1235\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 1236\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 1237\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.002894 \n",
      "\n",
      "Epoch 1238\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.002888 \n",
      "\n",
      "Epoch 1239\n",
      "-------------------------------\n",
      "loss: 0.001271  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002874 \n",
      "\n",
      "Epoch 1240\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1241\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.002851 \n",
      "\n",
      "Epoch 1242\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1243\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.002861 \n",
      "\n",
      "Epoch 1244\n",
      "-------------------------------\n",
      "loss: 0.001287  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002863 \n",
      "\n",
      "Epoch 1245\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002870 \n",
      "\n",
      "Epoch 1246\n",
      "-------------------------------\n",
      "loss: 0.001280  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1247\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 20.8%, Avg loss: 0.002839 \n",
      "\n",
      "Epoch 1248\n",
      "-------------------------------\n",
      "loss: 0.001269  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.6%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1249\n",
      "-------------------------------\n",
      "loss: 0.001266  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002845 \n",
      "\n",
      "Epoch 1250\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1251\n",
      "-------------------------------\n",
      "loss: 0.001284  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1252\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.3%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1253\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 1254\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1255\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1256\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002844 \n",
      "\n",
      "Epoch 1257\n",
      "-------------------------------\n",
      "loss: 0.001270  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002864 \n",
      "\n",
      "Epoch 1258\n",
      "-------------------------------\n",
      "loss: 0.001281  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002857 \n",
      "\n",
      "Epoch 1259\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.1%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1260\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.3%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1261\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 1262\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 1263\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 1264\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.3%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 1265\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1266\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.002866 \n",
      "\n",
      "Epoch 1267\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002857 \n",
      "\n",
      "Epoch 1268\n",
      "-------------------------------\n",
      "loss: 0.001272  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1269\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.002844 \n",
      "\n",
      "Epoch 1270\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.4%, Avg loss: 0.002837 \n",
      "\n",
      "Epoch 1271\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.0%, Avg loss: 0.002839 \n",
      "\n",
      "Epoch 1272\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.2%, Avg loss: 0.002840 \n",
      "\n",
      "Epoch 1273\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.9%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1274\n",
      "-------------------------------\n",
      "loss: 0.001264  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.2%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1275\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002851 \n",
      "\n",
      "Epoch 1276\n",
      "-------------------------------\n",
      "loss: 0.001266  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 1277\n",
      "-------------------------------\n",
      "loss: 0.001266  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1278\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1279\n",
      "-------------------------------\n",
      "loss: 0.001265  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1280\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.5%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1281\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1282\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1283\n",
      "-------------------------------\n",
      "loss: 0.001278  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.002844 \n",
      "\n",
      "Epoch 1284\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 0.002851 \n",
      "\n",
      "Epoch 1285\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1286\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1287\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1288\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1289\n",
      "-------------------------------\n",
      "loss: 0.001264  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.6%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1290\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1291\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002863 \n",
      "\n",
      "Epoch 1292\n",
      "-------------------------------\n",
      "loss: 0.001277  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 1293\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1294\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.1%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1295\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1296\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1297\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1298\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1299\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 1300\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 1301\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 1302\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 1303\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.002845 \n",
      "\n",
      "Epoch 1304\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1305\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1306\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002821 \n",
      "\n",
      "Epoch 1307\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.5%, Avg loss: 0.002831 \n",
      "\n",
      "Epoch 1308\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002820 \n",
      "\n",
      "Epoch 1309\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 1310\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1311\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.3%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1312\n",
      "-------------------------------\n",
      "loss: 0.001252  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1313\n",
      "-------------------------------\n",
      "loss: 0.001269  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.0%, Avg loss: 0.002820 \n",
      "\n",
      "Epoch 1314\n",
      "-------------------------------\n",
      "loss: 0.001270  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1315\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1316\n",
      "-------------------------------\n",
      "loss: 0.001264  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 1317\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.7%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1318\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1319\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1320\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 1321\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002571 \n",
      "\n",
      "Epoch 1322\n",
      "-------------------------------\n",
      "loss: 0.001253  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002529 \n",
      "\n",
      "Epoch 1323\n",
      "-------------------------------\n",
      "loss: 0.001264  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.002620 \n",
      "\n",
      "Epoch 1324\n",
      "-------------------------------\n",
      "loss: 0.001272  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 0.002696 \n",
      "\n",
      "Epoch 1325\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.1%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 1326\n",
      "-------------------------------\n",
      "loss: 0.001292  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.002919 \n",
      "\n",
      "Epoch 1327\n",
      "-------------------------------\n",
      "loss: 0.001321  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.2%, Avg loss: 0.002785 \n",
      "\n",
      "Epoch 1328\n",
      "-------------------------------\n",
      "loss: 0.001302  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1329\n",
      "-------------------------------\n",
      "loss: 0.001279  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 1330\n",
      "-------------------------------\n",
      "loss: 0.001273  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1331\n",
      "-------------------------------\n",
      "loss: 0.001271  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002794 \n",
      "\n",
      "Epoch 1332\n",
      "-------------------------------\n",
      "loss: 0.001268  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 1333\n",
      "-------------------------------\n",
      "loss: 0.001264  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 0.002800 \n",
      "\n",
      "Epoch 1334\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 1335\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.4%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 1336\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 1337\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 1338\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1339\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1340\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.8%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 1341\n",
      "-------------------------------\n",
      "loss: 0.001260  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.1%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1342\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1343\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1344\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.002832 \n",
      "\n",
      "Epoch 1345\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.7%, Avg loss: 0.002836 \n",
      "\n",
      "Epoch 1346\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.2%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 1347\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.6%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1348\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002842 \n",
      "\n",
      "Epoch 1349\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002844 \n",
      "\n",
      "Epoch 1350\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1351\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002850 \n",
      "\n",
      "Epoch 1352\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002863 \n",
      "\n",
      "Epoch 1353\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.0%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1354\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 1355\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 1356\n",
      "-------------------------------\n",
      "loss: 0.001269  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002869 \n",
      "\n",
      "Epoch 1357\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.002864 \n",
      "\n",
      "Epoch 1358\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 1359\n",
      "-------------------------------\n",
      "loss: 0.001252  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002863 \n",
      "\n",
      "Epoch 1360\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1361\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 1362\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002860 \n",
      "\n",
      "Epoch 1363\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1364\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 1365\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002865 \n",
      "\n",
      "Epoch 1366\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002878 \n",
      "\n",
      "Epoch 1367\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 0.002870 \n",
      "\n",
      "Epoch 1368\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002891 \n",
      "\n",
      "Epoch 1369\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002876 \n",
      "\n",
      "Epoch 1370\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 0.002889 \n",
      "\n",
      "Epoch 1371\n",
      "-------------------------------\n",
      "loss: 0.001276  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002884 \n",
      "\n",
      "Epoch 1372\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002886 \n",
      "\n",
      "Epoch 1373\n",
      "-------------------------------\n",
      "loss: 0.001252  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002879 \n",
      "\n",
      "Epoch 1374\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002870 \n",
      "\n",
      "Epoch 1375\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002873 \n",
      "\n",
      "Epoch 1376\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.002866 \n",
      "\n",
      "Epoch 1377\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002877 \n",
      "\n",
      "Epoch 1378\n",
      "-------------------------------\n",
      "loss: 0.001262  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1379\n",
      "-------------------------------\n",
      "loss: 0.001253  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002858 \n",
      "\n",
      "Epoch 1380\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002883 \n",
      "\n",
      "Epoch 1381\n",
      "-------------------------------\n",
      "loss: 0.001267  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002855 \n",
      "\n",
      "Epoch 1382\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002857 \n",
      "\n",
      "Epoch 1383\n",
      "-------------------------------\n",
      "loss: 0.001263  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.4%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1384\n",
      "-------------------------------\n",
      "loss: 0.001252  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 0.002856 \n",
      "\n",
      "Epoch 1385\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 1386\n",
      "-------------------------------\n",
      "loss: 0.001247  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.8%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1387\n",
      "-------------------------------\n",
      "loss: 0.001255  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 33.1%, Avg loss: 0.002847 \n",
      "\n",
      "Epoch 1388\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1389\n",
      "-------------------------------\n",
      "loss: 0.001247  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1390\n",
      "-------------------------------\n",
      "loss: 0.001261  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1391\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1392\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002853 \n",
      "\n",
      "Epoch 1393\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1394\n",
      "-------------------------------\n",
      "loss: 0.001253  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1395\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002849 \n",
      "\n",
      "Epoch 1396\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002852 \n",
      "\n",
      "Epoch 1397\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002848 \n",
      "\n",
      "Epoch 1398\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.6%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1399\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002831 \n",
      "\n",
      "Epoch 1400\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.3%, Avg loss: 0.002826 \n",
      "\n",
      "Epoch 1401\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1402\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.0%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 1403\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 1404\n",
      "-------------------------------\n",
      "loss: 0.001243  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.6%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 1405\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002832 \n",
      "\n",
      "Epoch 1406\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.9%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1407\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 59.4%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 1408\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1409\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.4%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 1410\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 1411\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 1412\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1413\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 1414\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002826 \n",
      "\n",
      "Epoch 1415\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002828 \n",
      "\n",
      "Epoch 1416\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.4%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 1417\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.002843 \n",
      "\n",
      "Epoch 1418\n",
      "-------------------------------\n",
      "loss: 0.001252  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1419\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 1420\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 1421\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 1422\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1423\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.4%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 1424\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 1425\n",
      "-------------------------------\n",
      "loss: 0.001258  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.4%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1426\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1427\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1428\n",
      "-------------------------------\n",
      "loss: 0.001266  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 1429\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002830 \n",
      "\n",
      "Epoch 1430\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.5%, Avg loss: 0.002827 \n",
      "\n",
      "Epoch 1431\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1432\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1433\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.2%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1434\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1435\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1436\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 1437\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.8%, Avg loss: 0.002814 \n",
      "\n",
      "Epoch 1438\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.002823 \n",
      "\n",
      "Epoch 1439\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.6%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 1440\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.1%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1441\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 1442\n",
      "-------------------------------\n",
      "loss: 0.001243  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.8%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 1443\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1444\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1445\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.4%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 1446\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.8%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1447\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 1448\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1449\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1450\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.5%, Avg loss: 0.002808 \n",
      "\n",
      "Epoch 1451\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.3%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1452\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 1453\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1454\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.5%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1455\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.8%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1456\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 1457\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 1458\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.002814 \n",
      "\n",
      "Epoch 1459\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1460\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.002809 \n",
      "\n",
      "Epoch 1461\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002814 \n",
      "\n",
      "Epoch 1462\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 1463\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1464\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.5%, Avg loss: 0.002809 \n",
      "\n",
      "Epoch 1465\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.6%, Avg loss: 0.002809 \n",
      "\n",
      "Epoch 1466\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1467\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1468\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.002574 \n",
      "\n",
      "Epoch 1469\n",
      "-------------------------------\n",
      "loss: 0.001240  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002525 \n",
      "\n",
      "Epoch 1470\n",
      "-------------------------------\n",
      "loss: 0.001250  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002605 \n",
      "\n",
      "Epoch 1471\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1472\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.2%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1473\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.002868 \n",
      "\n",
      "Epoch 1474\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.8%, Avg loss: 0.002902 \n",
      "\n",
      "Epoch 1475\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002909 \n",
      "\n",
      "Epoch 1476\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002931 \n",
      "\n",
      "Epoch 1477\n",
      "-------------------------------\n",
      "loss: 0.001246  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.1%, Avg loss: 0.002703 \n",
      "\n",
      "Epoch 1478\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 0.002606 \n",
      "\n",
      "Epoch 1479\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 0.002632 \n",
      "\n",
      "Epoch 1480\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 0.002668 \n",
      "\n",
      "Epoch 1481\n",
      "-------------------------------\n",
      "loss: 0.001247  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1482\n",
      "-------------------------------\n",
      "loss: 0.001275  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1483\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.1%, Avg loss: 0.002979 \n",
      "\n",
      "Epoch 1484\n",
      "-------------------------------\n",
      "loss: 0.001272  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 0.002725 \n",
      "\n",
      "Epoch 1485\n",
      "-------------------------------\n",
      "loss: 0.001269  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002649 \n",
      "\n",
      "Epoch 1486\n",
      "-------------------------------\n",
      "loss: 0.001256  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.002632 \n",
      "\n",
      "Epoch 1487\n",
      "-------------------------------\n",
      "loss: 0.001259  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.0%, Avg loss: 0.002650 \n",
      "\n",
      "Epoch 1488\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002688 \n",
      "\n",
      "Epoch 1489\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002717 \n",
      "\n",
      "Epoch 1490\n",
      "-------------------------------\n",
      "loss: 0.001257  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1491\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.7%, Avg loss: 0.002719 \n",
      "\n",
      "Epoch 1492\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1493\n",
      "-------------------------------\n",
      "loss: 0.001254  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1494\n",
      "-------------------------------\n",
      "loss: 0.001248  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.5%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1495\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1496\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 30.4%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1497\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 1498\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.4%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1499\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.6%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1501\n",
      "-------------------------------\n",
      "loss: 0.001244  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.002765 \n",
      "\n",
      "Epoch 1502\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.0%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1503\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1504\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.0%, Avg loss: 0.002770 \n",
      "\n",
      "Epoch 1505\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002765 \n",
      "\n",
      "Epoch 1506\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 1507\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.4%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1508\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.2%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1509\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 35.8%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 1510\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1511\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1512\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002766 \n",
      "\n",
      "Epoch 1513\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.1%, Avg loss: 0.002776 \n",
      "\n",
      "Epoch 1514\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.5%, Avg loss: 0.002778 \n",
      "\n",
      "Epoch 1515\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 1516\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.5%, Avg loss: 0.002785 \n",
      "\n",
      "Epoch 1517\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.002788 \n",
      "\n",
      "Epoch 1518\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.002783 \n",
      "\n",
      "Epoch 1519\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1520\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002788 \n",
      "\n",
      "Epoch 1521\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1522\n",
      "-------------------------------\n",
      "loss: 0.001242  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.4%, Avg loss: 0.002780 \n",
      "\n",
      "Epoch 1523\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1524\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1525\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1526\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002783 \n",
      "\n",
      "Epoch 1527\n",
      "-------------------------------\n",
      "loss: 0.001229  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1528\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.4%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 1529\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1530\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1531\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 1532\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.4%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1533\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.8%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 1534\n",
      "-------------------------------\n",
      "loss: 0.001229  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 1535\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 36.1%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1536\n",
      "-------------------------------\n",
      "loss: 0.001236  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1537\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.2%, Avg loss: 0.002791 \n",
      "\n",
      "Epoch 1538\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1539\n",
      "-------------------------------\n",
      "loss: 0.001245  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 1540\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.3%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 1541\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1542\n",
      "-------------------------------\n",
      "loss: 0.001241  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 1543\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1544\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.1%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1545\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1546\n",
      "-------------------------------\n",
      "loss: 0.001251  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1547\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1548\n",
      "-------------------------------\n",
      "loss: 0.001226  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 1549\n",
      "-------------------------------\n",
      "loss: 0.001229  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 0.002796 \n",
      "\n",
      "Epoch 1550\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1551\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1552\n",
      "-------------------------------\n",
      "loss: 0.001226  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002791 \n",
      "\n",
      "Epoch 1553\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1554\n",
      "-------------------------------\n",
      "loss: 0.001247  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002795 \n",
      "\n",
      "Epoch 1555\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1556\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002788 \n",
      "\n",
      "Epoch 1557\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 24.4%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1558\n",
      "-------------------------------\n",
      "loss: 0.001226  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1559\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 1560\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1561\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 1562\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002785 \n",
      "\n",
      "Epoch 1563\n",
      "-------------------------------\n",
      "loss: 0.001230  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002791 \n",
      "\n",
      "Epoch 1564\n",
      "-------------------------------\n",
      "loss: 0.001226  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1565\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1566\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 1567\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 1568\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.1%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 1569\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1570\n",
      "-------------------------------\n",
      "loss: 0.001226  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.8%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 1571\n",
      "-------------------------------\n",
      "loss: 0.001249  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.1%, Avg loss: 0.002784 \n",
      "\n",
      "Epoch 1572\n",
      "-------------------------------\n",
      "loss: 0.001225  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.8%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 1573\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.002784 \n",
      "\n",
      "Epoch 1574\n",
      "-------------------------------\n",
      "loss: 0.001235  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002797 \n",
      "\n",
      "Epoch 1575\n",
      "-------------------------------\n",
      "loss: 0.001225  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1576\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002791 \n",
      "\n",
      "Epoch 1577\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1578\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 1579\n",
      "-------------------------------\n",
      "loss: 0.001223  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1580\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1581\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.3%, Avg loss: 0.002786 \n",
      "\n",
      "Epoch 1582\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.3%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 1583\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1584\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.9%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1585\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1586\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 0.002726 \n",
      "\n",
      "Epoch 1587\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.0%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 1588\n",
      "-------------------------------\n",
      "loss: 0.001220  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1589\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.6%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1590\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.002755 \n",
      "\n",
      "Epoch 1591\n",
      "-------------------------------\n",
      "loss: 0.001225  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1592\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1593\n",
      "-------------------------------\n",
      "loss: 0.001223  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.002778 \n",
      "\n",
      "Epoch 1594\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.002753 \n",
      "\n",
      "Epoch 1595\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 1596\n",
      "-------------------------------\n",
      "loss: 0.001224  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1597\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1598\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1599\n",
      "-------------------------------\n",
      "loss: 0.001219  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.6%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 1600\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 1601\n",
      "-------------------------------\n",
      "loss: 0.001234  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.7%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 1602\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.0%, Avg loss: 0.002755 \n",
      "\n",
      "Epoch 1603\n",
      "-------------------------------\n",
      "loss: 0.001220  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1604\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1605\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.9%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1606\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 1607\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1608\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1609\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1610\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1611\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1612\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.1%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1613\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1614\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1615\n",
      "-------------------------------\n",
      "loss: 0.001219  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1616\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 1617\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1618\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1619\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 1620\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.8%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1621\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 1622\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1623\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1624\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002726 \n",
      "\n",
      "Epoch 1625\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.4%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1626\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.1%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1627\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1628\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1629\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1630\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1631\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1632\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1633\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1634\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1635\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.0%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1636\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1637\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 1638\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.4%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1639\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1640\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1641\n",
      "-------------------------------\n",
      "loss: 0.001219  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.4%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1642\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1643\n",
      "-------------------------------\n",
      "loss: 0.001218  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.6%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1644\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.7%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 1645\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1646\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1647\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.6%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1648\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1649\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1650\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1651\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.9%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 1652\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1653\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1654\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1655\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 1656\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1657\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.2%, Avg loss: 0.002729 \n",
      "\n",
      "Epoch 1658\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.1%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1659\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1660\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1661\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.002727 \n",
      "\n",
      "Epoch 1662\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1663\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1664\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1665\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1666\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 20.0%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1667\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 0.002738 \n",
      "\n",
      "Epoch 1668\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 75.1%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1669\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1670\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1671\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1672\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 23.1%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1673\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.3%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1674\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 0.002726 \n",
      "\n",
      "Epoch 1675\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1676\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 89.3%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1677\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1678\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1679\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1680\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1681\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1682\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 25.2%, Avg loss: 0.002734 \n",
      "\n",
      "Epoch 1683\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1684\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1685\n",
      "-------------------------------\n",
      "loss: 0.001199  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.002726 \n",
      "\n",
      "Epoch 1686\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1687\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1688\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.7%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1689\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1690\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.4%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1691\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 16.9%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1692\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1693\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1694\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1695\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.7%, Avg loss: 0.002732 \n",
      "\n",
      "Epoch 1696\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.5%, Avg loss: 0.002725 \n",
      "\n",
      "Epoch 1697\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.5%, Avg loss: 0.002726 \n",
      "\n",
      "Epoch 1698\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.8%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1699\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 21.5%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1700\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.0%, Avg loss: 0.002727 \n",
      "\n",
      "Epoch 1701\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.2%, Avg loss: 0.002735 \n",
      "\n",
      "Epoch 1702\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.3%, Avg loss: 0.002480 \n",
      "\n",
      "Epoch 1703\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.0%, Avg loss: 0.002440 \n",
      "\n",
      "Epoch 1704\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 56.2%, Avg loss: 0.002531 \n",
      "\n",
      "Epoch 1705\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 0.002651 \n",
      "\n",
      "Epoch 1706\n",
      "-------------------------------\n",
      "loss: 0.001216  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1707\n",
      "-------------------------------\n",
      "loss: 0.001219  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1708\n",
      "-------------------------------\n",
      "loss: 0.001227  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1709\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.002837 \n",
      "\n",
      "Epoch 1710\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002616 \n",
      "\n",
      "Epoch 1711\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.8%, Avg loss: 0.002519 \n",
      "\n",
      "Epoch 1712\n",
      "-------------------------------\n",
      "loss: 0.001206  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002554 \n",
      "\n",
      "Epoch 1713\n",
      "-------------------------------\n",
      "loss: 0.001217  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002635 \n",
      "\n",
      "Epoch 1714\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002720 \n",
      "\n",
      "Epoch 1715\n",
      "-------------------------------\n",
      "loss: 0.001233  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1716\n",
      "-------------------------------\n",
      "loss: 0.001231  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.7%, Avg loss: 0.002997 \n",
      "\n",
      "Epoch 1717\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.002702 \n",
      "\n",
      "Epoch 1718\n",
      "-------------------------------\n",
      "loss: 0.001232  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.2%, Avg loss: 0.002591 \n",
      "\n",
      "Epoch 1719\n",
      "-------------------------------\n",
      "loss: 0.001228  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 0.002556 \n",
      "\n",
      "Epoch 1720\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 0.002609 \n",
      "\n",
      "Epoch 1721\n",
      "-------------------------------\n",
      "loss: 0.001221  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.8%, Avg loss: 0.002649 \n",
      "\n",
      "Epoch 1722\n",
      "-------------------------------\n",
      "loss: 0.001220  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.0%, Avg loss: 0.002679 \n",
      "\n",
      "Epoch 1723\n",
      "-------------------------------\n",
      "loss: 0.001219  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.002692 \n",
      "\n",
      "Epoch 1724\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 0.002692 \n",
      "\n",
      "Epoch 1725\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.002701 \n",
      "\n",
      "Epoch 1726\n",
      "-------------------------------\n",
      "loss: 0.001214  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.4%, Avg loss: 0.002694 \n",
      "\n",
      "Epoch 1727\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.5%, Avg loss: 0.002688 \n",
      "\n",
      "Epoch 1728\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 0.002692 \n",
      "\n",
      "Epoch 1729\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002699 \n",
      "\n",
      "Epoch 1730\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002699 \n",
      "\n",
      "Epoch 1731\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002709 \n",
      "\n",
      "Epoch 1732\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002718 \n",
      "\n",
      "Epoch 1733\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002727 \n",
      "\n",
      "Epoch 1734\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.1%, Avg loss: 0.002718 \n",
      "\n",
      "Epoch 1735\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 0.002722 \n",
      "\n",
      "Epoch 1736\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 0.002724 \n",
      "\n",
      "Epoch 1737\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 0.002728 \n",
      "\n",
      "Epoch 1738\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 1739\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 21.0%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1740\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1741\n",
      "-------------------------------\n",
      "loss: 0.001208  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.7%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1742\n",
      "-------------------------------\n",
      "loss: 0.001203  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.0%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1743\n",
      "-------------------------------\n",
      "loss: 0.001204  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1744\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1745\n",
      "-------------------------------\n",
      "loss: 0.001205  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 7.5%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1746\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.7%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1747\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 29.6%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1748\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1749\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002770 \n",
      "\n",
      "Epoch 1750\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1751\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002774 \n",
      "\n",
      "Epoch 1752\n",
      "-------------------------------\n",
      "loss: 0.001215  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002788 \n",
      "\n",
      "Epoch 1753\n",
      "-------------------------------\n",
      "loss: 0.001222  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 1754\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 1755\n",
      "-------------------------------\n",
      "loss: 0.001198  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1756\n",
      "-------------------------------\n",
      "loss: 0.001209  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1757\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.2%, Avg loss: 0.002772 \n",
      "\n",
      "Epoch 1758\n",
      "-------------------------------\n",
      "loss: 0.001199  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1759\n",
      "-------------------------------\n",
      "loss: 0.001211  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.002760 \n",
      "\n",
      "Epoch 1760\n",
      "-------------------------------\n",
      "loss: 0.001198  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.1%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 1761\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 0.002773 \n",
      "\n",
      "Epoch 1762\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1763\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002772 \n",
      "\n",
      "Epoch 1764\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 1765\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002759 \n",
      "\n",
      "Epoch 1766\n",
      "-------------------------------\n",
      "loss: 0.001199  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.8%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 1767\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.002764 \n",
      "\n",
      "Epoch 1768\n",
      "-------------------------------\n",
      "loss: 0.001200  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1769\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 73.8%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1770\n",
      "-------------------------------\n",
      "loss: 0.001195  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.1%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1771\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1772\n",
      "-------------------------------\n",
      "loss: 0.001210  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002781 \n",
      "\n",
      "Epoch 1773\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1774\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002766 \n",
      "\n",
      "Epoch 1775\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.0%, Avg loss: 0.002826 \n",
      "\n",
      "Epoch 1776\n",
      "-------------------------------\n",
      "loss: 0.001237  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002783 \n",
      "\n",
      "Epoch 1777\n",
      "-------------------------------\n",
      "loss: 0.001212  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.002773 \n",
      "\n",
      "Epoch 1778\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 1779\n",
      "-------------------------------\n",
      "loss: 0.001238  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 0.002766 \n",
      "\n",
      "Epoch 1780\n",
      "-------------------------------\n",
      "loss: 0.001193  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1781\n",
      "-------------------------------\n",
      "loss: 0.001239  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1782\n",
      "-------------------------------\n",
      "loss: 0.001213  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1783\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.6%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 1784\n",
      "-------------------------------\n",
      "loss: 0.001193  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 1785\n",
      "-------------------------------\n",
      "loss: 0.001223  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1786\n",
      "-------------------------------\n",
      "loss: 0.001202  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002799 \n",
      "\n",
      "Epoch 1787\n",
      "-------------------------------\n",
      "loss: 0.001207  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1788\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002776 \n",
      "\n",
      "Epoch 1789\n",
      "-------------------------------\n",
      "loss: 0.001198  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.8%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1790\n",
      "-------------------------------\n",
      "loss: 0.001196  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.4%, Avg loss: 0.002772 \n",
      "\n",
      "Epoch 1791\n",
      "-------------------------------\n",
      "loss: 0.001198  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002771 \n",
      "\n",
      "Epoch 1792\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.002764 \n",
      "\n",
      "Epoch 1793\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.002763 \n",
      "\n",
      "Epoch 1794\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.002769 \n",
      "\n",
      "Epoch 1795\n",
      "-------------------------------\n",
      "loss: 0.001191  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.9%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1796\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1797\n",
      "-------------------------------\n",
      "loss: 0.001197  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002776 \n",
      "\n",
      "Epoch 1798\n",
      "-------------------------------\n",
      "loss: 0.001193  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1799\n",
      "-------------------------------\n",
      "loss: 0.001193  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1800\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1801\n",
      "-------------------------------\n",
      "loss: 0.001188  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1802\n",
      "-------------------------------\n",
      "loss: 0.001196  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002767 \n",
      "\n",
      "Epoch 1803\n",
      "-------------------------------\n",
      "loss: 0.001192  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002770 \n",
      "\n",
      "Epoch 1804\n",
      "-------------------------------\n",
      "loss: 0.001192  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002775 \n",
      "\n",
      "Epoch 1805\n",
      "-------------------------------\n",
      "loss: 0.001193  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.8%, Avg loss: 0.002787 \n",
      "\n",
      "Epoch 1806\n",
      "-------------------------------\n",
      "loss: 0.001199  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002779 \n",
      "\n",
      "Epoch 1807\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002773 \n",
      "\n",
      "Epoch 1808\n",
      "-------------------------------\n",
      "loss: 0.001192  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.4%, Avg loss: 0.002789 \n",
      "\n",
      "Epoch 1809\n",
      "-------------------------------\n",
      "loss: 0.001201  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.002777 \n",
      "\n",
      "Epoch 1810\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.002778 \n",
      "\n",
      "Epoch 1811\n",
      "-------------------------------\n",
      "loss: 0.001192  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002793 \n",
      "\n",
      "Epoch 1812\n",
      "-------------------------------\n",
      "loss: 0.001198  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002772 \n",
      "\n",
      "Epoch 1813\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1814\n",
      "-------------------------------\n",
      "loss: 0.001191  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 27.1%, Avg loss: 0.002777 \n",
      "\n",
      "Epoch 1815\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002792 \n",
      "\n",
      "Epoch 1816\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.002776 \n",
      "\n",
      "Epoch 1817\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002768 \n",
      "\n",
      "Epoch 1818\n",
      "-------------------------------\n",
      "loss: 0.001196  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.0%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1819\n",
      "-------------------------------\n",
      "loss: 0.001191  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.6%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1820\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 30.0%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1821\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1822\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1823\n",
      "-------------------------------\n",
      "loss: 0.001195  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.002755 \n",
      "\n",
      "Epoch 1824\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1825\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002756 \n",
      "\n",
      "Epoch 1826\n",
      "-------------------------------\n",
      "loss: 0.001194  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1827\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1828\n",
      "-------------------------------\n",
      "loss: 0.001190  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1829\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1830\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1831\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1832\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1833\n",
      "-------------------------------\n",
      "loss: 0.001186  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002753 \n",
      "\n",
      "Epoch 1834\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1835\n",
      "-------------------------------\n",
      "loss: 0.001186  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1836\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1837\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1838\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1839\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1840\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 31.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1841\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1842\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1843\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1844\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 20.7%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1845\n",
      "-------------------------------\n",
      "loss: 0.001181  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1846\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1847\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1848\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.3%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1849\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1850\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1851\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.6%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1852\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1853\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1854\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1855\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1856\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1857\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1858\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 8.6%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1859\n",
      "-------------------------------\n",
      "loss: 0.001187  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1860\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1861\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.7%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1862\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1863\n",
      "-------------------------------\n",
      "loss: 0.001180  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1864\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.6%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1865\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1866\n",
      "-------------------------------\n",
      "loss: 0.001180  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1867\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1868\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1869\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 1870\n",
      "-------------------------------\n",
      "loss: 0.001181  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002754 \n",
      "\n",
      "Epoch 1871\n",
      "-------------------------------\n",
      "loss: 0.001186  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1872\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1873\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.9%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1874\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 15.8%, Avg loss: 0.002753 \n",
      "\n",
      "Epoch 1875\n",
      "-------------------------------\n",
      "loss: 0.001181  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 1876\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1877\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.2%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1878\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1879\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.2%, Avg loss: 0.002749 \n",
      "\n",
      "Epoch 1880\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.7%, Avg loss: 0.002758 \n",
      "\n",
      "Epoch 1881\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 5.6%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1882\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1883\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1884\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1885\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 1886\n",
      "-------------------------------\n",
      "loss: 0.001179  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 0.002751 \n",
      "\n",
      "Epoch 1887\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.4%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1888\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002750 \n",
      "\n",
      "Epoch 1889\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 11.1%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1890\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1891\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.4%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1892\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1893\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 19.3%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1894\n",
      "-------------------------------\n",
      "loss: 0.001180  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1895\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1896\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002739 \n",
      "\n",
      "Epoch 1897\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1898\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1899\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1900\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1901\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1902\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.4%, Avg loss: 0.002738 \n",
      "\n",
      "Epoch 1903\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.6%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1904\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1905\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1906\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1907\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 34.2%, Avg loss: 0.002742 \n",
      "\n",
      "Epoch 1908\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 0.002738 \n",
      "\n",
      "Epoch 1909\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1910\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 32.9%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1911\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1912\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.2%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1913\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.7%, Avg loss: 0.002740 \n",
      "\n",
      "Epoch 1914\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.9%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1915\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1916\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1917\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 1918\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1919\n",
      "-------------------------------\n",
      "loss: 0.001176  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002748 \n",
      "\n",
      "Epoch 1920\n",
      "-------------------------------\n",
      "loss: 0.001171  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.5%, Avg loss: 0.002747 \n",
      "\n",
      "Epoch 1921\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.4%, Avg loss: 0.002746 \n",
      "\n",
      "Epoch 1922\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1923\n",
      "-------------------------------\n",
      "loss: 0.001186  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 13.3%, Avg loss: 0.002738 \n",
      "\n",
      "Epoch 1924\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002738 \n",
      "\n",
      "Epoch 1925\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 0.002744 \n",
      "\n",
      "Epoch 1926\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002762 \n",
      "\n",
      "Epoch 1927\n",
      "-------------------------------\n",
      "loss: 0.001180  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.002757 \n",
      "\n",
      "Epoch 1928\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002752 \n",
      "\n",
      "Epoch 1929\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.7%, Avg loss: 0.002745 \n",
      "\n",
      "Epoch 1930\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.3%, Avg loss: 0.002741 \n",
      "\n",
      "Epoch 1931\n",
      "-------------------------------\n",
      "loss: 0.001164  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 0.002733 \n",
      "\n",
      "Epoch 1932\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002743 \n",
      "\n",
      "Epoch 1933\n",
      "-------------------------------\n",
      "loss: 0.001182  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002730 \n",
      "\n",
      "Epoch 1934\n",
      "-------------------------------\n",
      "loss: 0.001167  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002731 \n",
      "\n",
      "Epoch 1935\n",
      "-------------------------------\n",
      "loss: 0.001167  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 0.002736 \n",
      "\n",
      "Epoch 1936\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.2%, Avg loss: 0.002737 \n",
      "\n",
      "Epoch 1937\n",
      "-------------------------------\n",
      "loss: 0.001171  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002493 \n",
      "\n",
      "Epoch 1938\n",
      "-------------------------------\n",
      "loss: 0.001189  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.002407 \n",
      "\n",
      "Epoch 1939\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.002500 \n",
      "\n",
      "Epoch 1940\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002631 \n",
      "\n",
      "Epoch 1941\n",
      "-------------------------------\n",
      "loss: 0.001183  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.9%, Avg loss: 0.002719 \n",
      "\n",
      "Epoch 1942\n",
      "-------------------------------\n",
      "loss: 0.001184  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 12.2%, Avg loss: 0.002770 \n",
      "\n",
      "Epoch 1943\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 0.002801 \n",
      "\n",
      "Epoch 1944\n",
      "-------------------------------\n",
      "loss: 0.001181  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.9%, Avg loss: 0.002808 \n",
      "\n",
      "Epoch 1945\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.0%, Avg loss: 0.002808 \n",
      "\n",
      "Epoch 1946\n",
      "-------------------------------\n",
      "loss: 0.001174  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1947\n",
      "-------------------------------\n",
      "loss: 0.001177  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 4.8%, Avg loss: 0.002809 \n",
      "\n",
      "Epoch 1948\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.5%, Avg loss: 0.002820 \n",
      "\n",
      "Epoch 1949\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 1950\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1951\n",
      "-------------------------------\n",
      "loss: 0.001171  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 37.5%, Avg loss: 0.002808 \n",
      "\n",
      "Epoch 1952\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 10.7%, Avg loss: 0.002804 \n",
      "\n",
      "Epoch 1953\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1954\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002798 \n",
      "\n",
      "Epoch 1955\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1956\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.002804 \n",
      "\n",
      "Epoch 1957\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.002805 \n",
      "\n",
      "Epoch 1958\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1959\n",
      "-------------------------------\n",
      "loss: 0.001170  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1960\n",
      "-------------------------------\n",
      "loss: 0.001167  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.002810 \n",
      "\n",
      "Epoch 1961\n",
      "-------------------------------\n",
      "loss: 0.001167  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1962\n",
      "-------------------------------\n",
      "loss: 0.001167  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1963\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002807 \n",
      "\n",
      "Epoch 1964\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.002806 \n",
      "\n",
      "Epoch 1965\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1966\n",
      "-------------------------------\n",
      "loss: 0.001161  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1967\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.002802 \n",
      "\n",
      "Epoch 1968\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.002802 \n",
      "\n",
      "Epoch 1969\n",
      "-------------------------------\n",
      "loss: 0.001164  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.1%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 1970\n",
      "-------------------------------\n",
      "loss: 0.001170  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1971\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1972\n",
      "-------------------------------\n",
      "loss: 0.001163  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.002816 \n",
      "\n",
      "Epoch 1973\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.002811 \n",
      "\n",
      "Epoch 1974\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 6.4%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1975\n",
      "-------------------------------\n",
      "loss: 0.001166  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1976\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.8%, Avg loss: 0.002838 \n",
      "\n",
      "Epoch 1977\n",
      "-------------------------------\n",
      "loss: 0.001178  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Avg loss: 0.002829 \n",
      "\n",
      "Epoch 1978\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.002817 \n",
      "\n",
      "Epoch 1979\n",
      "-------------------------------\n",
      "loss: 0.001162  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.002819 \n",
      "\n",
      "Epoch 1980\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 0.002836 \n",
      "\n",
      "Epoch 1981\n",
      "-------------------------------\n",
      "loss: 0.001185  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 9.0%, Avg loss: 0.002847 \n",
      "\n",
      "Epoch 1982\n",
      "-------------------------------\n",
      "loss: 0.001180  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 38.9%, Avg loss: 0.002825 \n",
      "\n",
      "Epoch 1983\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 0.002815 \n",
      "\n",
      "Epoch 1984\n",
      "-------------------------------\n",
      "loss: 0.001162  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 66.6%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 1985\n",
      "-------------------------------\n",
      "loss: 0.001173  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.002812 \n",
      "\n",
      "Epoch 1986\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 1987\n",
      "-------------------------------\n",
      "loss: 0.001169  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002822 \n",
      "\n",
      "Epoch 1988\n",
      "-------------------------------\n",
      "loss: 0.001164  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.002824 \n",
      "\n",
      "Epoch 1989\n",
      "-------------------------------\n",
      "loss: 0.001164  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 71.7%, Avg loss: 0.002834 \n",
      "\n",
      "Epoch 1990\n",
      "-------------------------------\n",
      "loss: 0.001170  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.002833 \n",
      "\n",
      "Epoch 1991\n",
      "-------------------------------\n",
      "loss: 0.001175  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.002831 \n",
      "\n",
      "Epoch 1992\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 72.9%, Avg loss: 0.002846 \n",
      "\n",
      "Epoch 1993\n",
      "-------------------------------\n",
      "loss: 0.001172  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.002818 \n",
      "\n",
      "Epoch 1994\n",
      "-------------------------------\n",
      "loss: 0.001168  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 14.3%, Avg loss: 0.002803 \n",
      "\n",
      "Epoch 1995\n",
      "-------------------------------\n",
      "loss: 0.001165  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 0.002854 \n",
      "\n",
      "Epoch 1996\n",
      "-------------------------------\n",
      "loss: 0.001162  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.002859 \n",
      "\n",
      "Epoch 1997\n",
      "-------------------------------\n",
      "loss: 0.001159  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 0.002841 \n",
      "\n",
      "Epoch 1998\n",
      "-------------------------------\n",
      "loss: 0.001160  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.2%, Avg loss: 0.002813 \n",
      "\n",
      "Epoch 1999\n",
      "-------------------------------\n",
      "loss: 0.001163  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 3.3%, Avg loss: 0.002790 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.001162  [    0/ 2500]\n",
      "2500\n",
      "Test Error: \n",
      " Accuracy: 17.9%, Avg loss: 0.002773 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd20c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "#If you want to save the model. \n",
    "#torch.save(model.state_dict(), \"Vanilla SGD model.pth\")\n",
    "#print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8337f1-8eed-4830-a236-4dbf6091fdf0",
   "metadata": {},
   "source": [
    "So as you can see our experiment ends in failure: \n",
    "it yoyos all over the place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6646e227-050d-4921-8604-f437e4d75211",
   "metadata": {},
   "source": [
    "The loss itself is not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b4e1f-6837-41af-914e-0f0eacc953ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
